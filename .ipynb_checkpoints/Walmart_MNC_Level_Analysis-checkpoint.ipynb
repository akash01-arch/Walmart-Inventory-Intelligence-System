{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¢ Walmart Inventory Intelligence System\n",
    "## MNC-Level Data Science Project\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Œ Project Overview\n",
    "| Item | Detail |\n",
    "|------|--------|\n",
    "| **Domain** | Retail Supply Chain & Inventory Management |\n",
    "| **Objective** | Build an end-to-end ML system to predict demand, classify stockout risk, and optimize inventory |\n",
    "| **Business Value** | Reduce lost revenue from stockouts + reduce working capital tied in overstock |\n",
    "| **Models Used** | Linear Regression, Ridge, Random Forest, Gradient Boosting |\n",
    "| **Techniques** | TimeSeriesSplit CV, Hyperparameter Tuning, SHAP Explainability, EOQ Model, Model Persistence |\n",
    "\n",
    "### ğŸ—ï¸ Project Architecture\n",
    "```\n",
    "Raw Data â†’ Cleaning Pipeline â†’ Feature Engineering â†’ EDA\n",
    "    â†’ Demand Forecasting Model (Regression)\n",
    "    â†’ Stockout Risk Model (Classification)\n",
    "    â†’ 30-Day Revenue Forecast\n",
    "    â†’ EOQ Inventory Optimization\n",
    "    â†’ Business Impact Quantification\n",
    "    â†’ Model Persistence (Production Ready)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Section 1: Environment Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ STANDARD LIBRARIES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# â”€â”€ MACHINE LEARNING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, TimeSeriesSplit,\n",
    "    RandomizedSearchCV, cross_val_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, RandomForestClassifier,\n",
    "    GradientBoostingRegressor, GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    accuracy_score, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# â”€â”€ PLOT STYLING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "plt.rcParams['figure.dpi']      = 120\n",
    "plt.rcParams['font.family']     = 'sans-serif'\n",
    "plt.rcParams['axes.spines.top']    = False\n",
    "plt.rcParams['axes.spines.right']  = False\n",
    "sns.set_style('whitegrid')\n",
    "COLORS = ['#2196F3','#4CAF50','#FF9800','#F44336','#9C27B0','#00BCD4','#FF5722','#607D8B']\n",
    "\n",
    "# â”€â”€ OUTPUT FOLDER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "\n",
    "print('âœ… All libraries loaded successfully!')\n",
    "print(f'ğŸ“… Analysis Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Section 2: Data Loading & Production-Grade Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ LOAD DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_raw = pd.read_csv('Walmart-Inventory-Dataset.csv')\n",
    "\n",
    "print('=' * 55)\n",
    "print('         RAW DATA QUALITY REPORT')\n",
    "print('=' * 55)\n",
    "print(f'  Total Records      : {len(df_raw):,}')\n",
    "print(f'  Total Columns      : {df_raw.shape[1]}')\n",
    "print(f'  Duplicate Rows     : {df_raw.duplicated().sum()}')\n",
    "print(f'  Missing Values     : {df_raw.isnull().sum().sum()}')\n",
    "print(f'  Memory Usage       : {df_raw.memory_usage(deep=True).sum() / 1024:.1f} KB')\n",
    "print('=' * 55)\n",
    "print('\\nMissing Values Per Column:')\n",
    "missing = df_raw.isnull().sum()\n",
    "print(missing[missing > 0].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CLEANING PIPELINE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Step 1: Handle missing values\n",
    "df['promotion_type'] = df['promotion_type'].fillna('No Promotion')\n",
    "\n",
    "# Step 2: Fix data types\n",
    "df['transaction_date'] = pd.to_datetime(df['transaction_date'])\n",
    "\n",
    "# Step 3: Remove duplicates\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "print(f'Duplicates removed: {before - len(df)}')\n",
    "\n",
    "# Step 4: Date features â€” critical for time series ML\n",
    "df['year']        = df['transaction_date'].dt.year\n",
    "df['month']       = df['transaction_date'].dt.month\n",
    "df['week']        = df['transaction_date'].dt.isocalendar().week.astype(int)\n",
    "df['day_of_week'] = df['transaction_date'].dt.dayofweek\n",
    "df['quarter']     = df['transaction_date'].dt.quarter\n",
    "df['is_weekend']  = (df['day_of_week'] >= 5).astype(int)\n",
    "df['YearMonth']   = df['transaction_date'].dt.to_period('M')\n",
    "\n",
    "# Step 5: Business metric features\n",
    "df['revenue']            = df['quantity_sold'] * df['unit_price']\n",
    "df['forecast_error']     = abs(df['forecasted_demand'] - df['actual_demand'])\n",
    "df['forecast_bias']      = df['forecasted_demand'] - df['actual_demand']\n",
    "df['lost_sales_qty']     = (df['actual_demand'] - df['forecasted_demand']).clip(lower=0)\n",
    "df['lost_revenue']       = df['lost_sales_qty'] * df['unit_price']\n",
    "df['excess_inventory']   = (df['inventory_level'] - df['reorder_point']).clip(lower=0)\n",
    "df['days_of_stock']      = (df['inventory_level'] / df['actual_demand'].replace(0, np.nan)).fillna(0)\n",
    "df['stock_health']       = (df['inventory_level'] / df['reorder_point'].replace(0, np.nan)).fillna(0)\n",
    "df['is_promotion']       = (df['promotion_type'] != 'No Promotion').astype(int)\n",
    "df['demand_vs_forecast'] = df['actual_demand'] / df['forecasted_demand'].replace(0, np.nan)\n",
    "df['price_tier']         = pd.qcut(df['unit_price'], q=4, labels=['Budget','Mid','Premium','Luxury'])\n",
    "\n",
    "# Step 6: Buyer type\n",
    "orders_per_customer = df.groupby('customer_id')['transaction_id'].count().reset_index()\n",
    "orders_per_customer.rename(columns={'transaction_id': 'order_count'}, inplace=True)\n",
    "orders_per_customer['buyer_type'] = orders_per_customer['order_count'].apply(\n",
    "    lambda x: 'Repeat Buyer' if x > 1 else 'One-time Buyer'\n",
    ")\n",
    "df = df.merge(orders_per_customer[['customer_id','buyer_type']], on='customer_id', how='left')\n",
    "\n",
    "print('\\nâœ… Data cleaning pipeline complete!')\n",
    "print(f'   Final records  : {len(df):,}')\n",
    "print(f'   Total features : {df.shape[1]}')\n",
    "print(f'   Date range     : {df[\"transaction_date\"].min().date()} â†’ {df[\"transaction_date\"].max().date()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Section 3: Executive KPI Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ COMPUTE ALL KPIs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "total_revenue       = df['revenue'].sum()\n",
    "total_lost_revenue  = df['lost_revenue'].sum()\n",
    "stockout_rate       = df['stockout_indicator'].mean() * 100\n",
    "avg_forecast_err    = df['forecast_error'].mean()\n",
    "overstock_count     = (df['stock_health'] > 2).sum()\n",
    "understock_count    = (df['stock_health'] < 1).sum()\n",
    "repeat_rate         = (orders_per_customer['order_count'] > 1).mean() * 100\n",
    "forecast_accuracy   = 100 - (df['forecast_error'] / df['actual_demand'].replace(0,np.nan)).mean() * 100\n",
    "\n",
    "kpis = [\n",
    "    ('ğŸ’° Total Revenue',      f'${total_revenue/1e6:.2f}M',     '#4CAF50'),\n",
    "    ('ğŸ“‰ Lost Revenue',       f'${total_lost_revenue/1e6:.1f}M', '#F44336'),\n",
    "    ('âš ï¸ Stockout Rate',      f'{stockout_rate:.1f}%',           '#FF9800'),\n",
    "    ('ğŸ¯ Forecast Accuracy',  f'{forecast_accuracy:.1f}%',       '#2196F3'),\n",
    "    ('ğŸ“¦ Overstock Items',    f'{overstock_count:,}',            '#9C27B0'),\n",
    "    ('ğŸ”´ Understock Items',   f'{understock_count:,}',           '#E91E63'),\n",
    "    ('ğŸ”„ Repeat Buyer Rate',  f'{repeat_rate:.1f}%',             '#00BCD4'),\n",
    "    ('ğŸ›’ Unique Products',    f'{df[\"product_name\"].nunique()}', '#607D8B'),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 7))\n",
    "fig.suptitle('ğŸ“Š Walmart Inventory â€” Executive KPI Dashboard', fontsize=16, fontweight='bold')\n",
    "fig.patch.set_facecolor('#f0f2f5')\n",
    "\n",
    "for ax, (title, value, color) in zip(axes.flat, kpis):\n",
    "    ax.set_facecolor('white')\n",
    "    ax.text(0.5, 0.58, value, ha='center', va='center',\n",
    "            fontsize=22, fontweight='bold', color=color, transform=ax.transAxes)\n",
    "    ax.text(0.5, 0.22, title, ha='center', va='center',\n",
    "            fontsize=9, color='#555', transform=ax.transAxes)\n",
    "    ax.axis('off')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor(color)\n",
    "        spine.set_linewidth(3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/kpi_dashboard.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "print('ğŸ’¾ Dashboard saved to reports/kpi_dashboard.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Section 4: Advanced EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ REVENUE TREND + CATEGORY BREAKDOWN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "monthly = df.groupby('YearMonth')['revenue'].sum().reset_index()\n",
    "monthly['YearMonth_str'] = monthly['YearMonth'].astype(str)\n",
    "monthly['rolling_3m']    = monthly['revenue'].rolling(3, min_periods=1).mean()\n",
    "monthly['MoM_growth']    = monthly['revenue'].pct_change() * 100\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Revenue & Demand Analysis', fontsize=15, fontweight='bold')\n",
    "\n",
    "# Plot 1: Monthly Revenue with Rolling Average\n",
    "ax = axes[0, 0]\n",
    "ax.bar(monthly['YearMonth_str'], monthly['revenue'], color='#2196F3', alpha=0.6, label='Monthly Revenue')\n",
    "ax.plot(monthly['YearMonth_str'], monthly['rolling_3m'], color='#F44336',\n",
    "        linewidth=2.5, marker='o', markersize=5, label='3-Month Rolling Avg')\n",
    "ax.set_title('Monthly Revenue Trend', fontweight='bold')\n",
    "ax.set_ylabel('Revenue (USD)')\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x,p: f'${x/1e3:.0f}K'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "# Plot 2: Category Revenue Share\n",
    "ax2 = axes[0, 1]\n",
    "cat_rev = df.groupby('category')['revenue'].sum().sort_values(ascending=False)\n",
    "wedges, texts, autotexts = ax2.pie(\n",
    "    cat_rev.values, labels=cat_rev.index,\n",
    "    autopct='%1.1f%%', colors=COLORS[:len(cat_rev)],\n",
    "    startangle=90, pctdistance=0.85\n",
    ")\n",
    "for t in autotexts:\n",
    "    t.set_fontsize(10)\n",
    "    t.set_fontweight('bold')\n",
    "ax2.set_title('Revenue Share by Category', fontweight='bold')\n",
    "\n",
    "# Plot 3: Seasonality Heatmap\n",
    "ax3 = axes[1, 0]\n",
    "pivot = df.pivot_table(values='revenue', index='month', columns='day_of_week', aggfunc='sum')\n",
    "pivot.columns = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "sns.heatmap(pivot, cmap='YlOrRd', annot=True, fmt='.0f',\n",
    "            annot_kws={'size': 7}, ax=ax3,\n",
    "            cbar_kws={'format': ticker.FuncFormatter(lambda x,p: f'${x/1e3:.0f}K')})\n",
    "ax3.set_title('ğŸ”¥ Revenue Heatmap: Month Ã— Day of Week', fontweight='bold')\n",
    "\n",
    "# Plot 4: Stockout vs Non-Stockout Revenue\n",
    "ax4 = axes[1, 1]\n",
    "stockout_rev = df.groupby(['month','stockout_indicator'])['revenue'].sum().unstack()\n",
    "stockout_rev.columns = ['No Stockout','Stockout']\n",
    "stockout_rev.plot(kind='bar', ax=ax4, color=['#4CAF50','#F44336'], alpha=0.8)\n",
    "ax4.set_title('Monthly Revenue: Stockout vs No Stockout', fontweight='bold')\n",
    "ax4.set_ylabel('Revenue')\n",
    "ax4.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x,p: f'${x/1e3:.0f}K'))\n",
    "ax4.tick_params(axis='x', rotation=0)\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/eda_analysis.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CORRELATION MATRIX â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "num_cols = ['actual_demand','forecasted_demand','inventory_level','unit_price',\n",
    "            'revenue','forecast_error','stock_health','days_of_stock','lost_revenue']\n",
    "\n",
    "corr = df[num_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            center=0, square=True, linewidths=0.5,\n",
    "            annot_kws={'size': 9})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/correlation_matrix.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Key insight\n",
    "inv_demand_corr = df['inventory_level'].corr(df['actual_demand'])\n",
    "print(f'\\nâš ï¸  Inventory â†” Demand Correlation: {inv_demand_corr:.4f}')\n",
    "print('    This near-zero correlation confirms inventory is NOT aligned with demand.')\n",
    "print('    Root cause of lost revenue and overstock problems.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Section 5: Demand Forecasting Model\n",
    "### Using TimeSeriesSplit CV + Hyperparameter Tuning (MNC Standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ LABEL ENCODING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_ml = df.copy()\n",
    "\n",
    "encoders = {}\n",
    "for col in ['category','store_location','product_name','promotion_type','price_tier','buyer_type']:\n",
    "    le = LabelEncoder()\n",
    "    df_ml[f'{col}_enc'] = le.fit_transform(df_ml[col].astype(str))\n",
    "    encoders[col] = le\n",
    "\n",
    "# â”€â”€ FEATURE SET â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DEMAND_FEATURES = [\n",
    "    # Time features\n",
    "    'year','month','week','day_of_week','quarter','is_weekend',\n",
    "    # Product / Store\n",
    "    'category_enc','store_location_enc','product_name_enc','promotion_type_enc','price_tier_enc',\n",
    "    # Inventory signals\n",
    "    'unit_price','inventory_level','reorder_point','stock_health','days_of_stock',\n",
    "    # Business signals\n",
    "    'is_promotion','forecasted_demand','forecast_error'\n",
    "]\n",
    "\n",
    "TARGET = 'actual_demand'\n",
    "\n",
    "# â”€â”€ TIME-BASED SPLIT (prevents data leakage) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_ml_sorted = df_ml.sort_values('transaction_date').reset_index(drop=True)\n",
    "X = df_ml_sorted[DEMAND_FEATURES].fillna(0)\n",
    "y = df_ml_sorted[TARGET]\n",
    "\n",
    "# 80/20 time-based split\n",
    "split_idx   = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print('âœ… Time-based split (no data leakage):')\n",
    "print(f'   Training : {len(X_train):,} records | {df_ml_sorted[\"transaction_date\"].iloc[0].date()} â†’ {df_ml_sorted[\"transaction_date\"].iloc[split_idx-1].date()}')\n",
    "print(f'   Testing  : {len(X_test):,}  records | {df_ml_sorted[\"transaction_date\"].iloc[split_idx].date()} â†’ {df_ml_sorted[\"transaction_date\"].iloc[-1].date()}')\n",
    "print(f'   Features : {len(DEMAND_FEATURES)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ HYPERPARAMETER TUNING WITH TimeSeriesSplit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('ğŸ” Running Hyperparameter Tuning (RandomizedSearchCV + TimeSeriesSplit)...')\n",
    "print('   This is the MNC-standard approach for time series models.')\n",
    "print()\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators'     : [100, 200, 300],\n",
    "    'max_depth'        : [5, 8, 10, None],\n",
    "    'min_samples_leaf' : [3, 5, 10],\n",
    "    'max_features'     : ['sqrt', 'log2', 0.7],\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    param_distributions = param_dist,\n",
    "    n_iter      = 15,\n",
    "    cv          = tscv,\n",
    "    scoring     = 'r2',\n",
    "    random_state= 42,\n",
    "    n_jobs      = -1,\n",
    "    verbose     = 0\n",
    ")\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'âœ… Best Parameters Found:')\n",
    "for k, v in rf_search.best_params_.items():\n",
    "    print(f'   {k:20s}: {v}')\n",
    "print(f'\\n   Best CV RÂ² Score: {rf_search.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ TRAIN ALL MODELS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "models = {\n",
    "    'Linear Regression' : LinearRegression(),\n",
    "    'Ridge Regression'  : Ridge(alpha=1.0),\n",
    "    'Random Forest'     : rf_search.best_estimator_,\n",
    "    'Gradient Boosting' : GradientBoostingRegressor(\n",
    "                            n_estimators=300, learning_rate=0.05,\n",
    "                            max_depth=5, subsample=0.8,\n",
    "                            min_samples_leaf=5, random_state=42\n",
    "                          ),\n",
    "}\n",
    "\n",
    "results = []\n",
    "predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name not in ['Random Forest']:  # already fitted via search\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    predictions[name] = pred\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "    mae  = mean_absolute_error(y_test, pred)\n",
    "    r2   = r2_score(y_test, pred)\n",
    "    mape = np.mean(np.abs((y_test - pred) / (y_test + 1e-8))) * 100\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring='r2')\n",
    "    \n",
    "    results.append({\n",
    "        'Model'       : name,\n",
    "        'RMSE'        : round(rmse, 2),\n",
    "        'MAE'         : round(mae, 2),\n",
    "        'RÂ² Score'    : round(r2, 4),\n",
    "        'MAPE (%)'    : round(mape, 2),\n",
    "        'CV RÂ² Mean'  : round(cv_scores.mean(), 4),\n",
    "        'CV RÂ² Std'   : round(cv_scores.std(), 4),\n",
    "    })\n",
    "    print(f'  âœ… {name:25s} | RÂ²={r2:.4f} | RMSE={rmse:.1f} | CV={cv_scores.mean():.4f}Â±{cv_scores.std():.4f}')\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('RÂ² Score', ascending=False)\n",
    "\n",
    "print('\\n' + '='*75)\n",
    "print('                DEMAND FORECASTING â€” MODEL LEADERBOARD')\n",
    "print('='*75)\n",
    "print(results_df.to_string(index=False))\n",
    "print('='*75)\n",
    "\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model      = models[best_model_name]\n",
    "best_pred       = predictions[best_model_name]\n",
    "print(f'\\nğŸ† Best Model: {best_model_name} (RÂ² = {results_df.iloc[0][\"RÂ² Score\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ MODEL COMPARISON VISUALIZATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Demand Forecasting â€” Model Evaluation', fontsize=15, fontweight='bold')\n",
    "\n",
    "sample = np.random.choice(len(y_test), min(300, len(y_test)), replace=False)\n",
    "y_sample = np.array(y_test)[sample]\n",
    "\n",
    "# Plot 1-3: Actual vs Predicted scatter for top 3 models\n",
    "plot_models = list(predictions.keys())[:3]\n",
    "for idx, (ax, name) in enumerate(zip([axes[0,0], axes[0,1], axes[1,0]], plot_models)):\n",
    "    p = predictions[name][sample]\n",
    "    r2 = r2_score(y_test, predictions[name])\n",
    "    ax.scatter(y_sample, p, alpha=0.4, color=COLORS[idx], s=25)\n",
    "    mn, mx = min(y_sample.min(), p.min()), max(y_sample.max(), p.max())\n",
    "    ax.plot([mn,mx],[mn,mx], 'r--', lw=2, label='Perfect Prediction')\n",
    "    ax.set_title(f'{name}\\nRÂ² = {r2:.4f}', fontweight='bold')\n",
    "    ax.set_xlabel('Actual Demand')\n",
    "    ax.set_ylabel('Predicted Demand')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "# Plot 4: Model Comparison Bar Chart\n",
    "ax4 = axes[1, 1]\n",
    "x = np.arange(len(results_df))\n",
    "bars = ax4.bar(results_df['Model'], results_df['RÂ² Score'],\n",
    "               color=COLORS[:len(results_df)], alpha=0.85)\n",
    "for bar, val in zip(bars, results_df['RÂ² Score']):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "             f'{val:.4f}', ha='center', fontsize=10, fontweight='bold')\n",
    "ax4.set_title('Model RÂ² Score Comparison', fontweight='bold')\n",
    "ax4.set_ylabel('RÂ² Score')\n",
    "ax4.set_ylim(0, 1.1)\n",
    "ax4.tick_params(axis='x', rotation=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/model_evaluation.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ FEATURE IMPORTANCE + RESIDUAL ANALYSIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "rf_model = models['Random Forest']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Feature Importance\n",
    "feat_imp = pd.Series(rf_model.feature_importances_, index=DEMAND_FEATURES).sort_values()\n",
    "colors_fi = ['#F44336' if v > feat_imp.quantile(0.75) else '#2196F3' for v in feat_imp.values]\n",
    "axes[0].barh(feat_imp.index, feat_imp.values, color=colors_fi)\n",
    "axes[0].set_title('ğŸ”‘ Feature Importance â€” What Drives Demand?', fontweight='bold')\n",
    "axes[0].set_xlabel('Importance Score')\n",
    "for i, (idx, val) in enumerate(feat_imp.items()):\n",
    "    axes[0].text(val + 0.001, i, f'{val:.3f}', va='center', fontsize=7)\n",
    "\n",
    "# Residual Distribution\n",
    "residuals = np.array(y_test) - best_pred\n",
    "axes[1].hist(residuals, bins=50, color='#2196F3', alpha=0.7, edgecolor='white')\n",
    "axes[1].axvline(0, color='red', linestyle='--', lw=2, label='Zero Error')\n",
    "axes[1].axvline(residuals.mean(), color='orange', linestyle='--', lw=2,\n",
    "                label=f'Mean={residuals.mean():.1f}')\n",
    "axes[1].set_title(f'Residual Distribution â€” {best_model_name}', fontweight='bold')\n",
    "axes[1].set_xlabel('Prediction Error (Actual - Predicted)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/feature_importance.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print('\\nğŸ“Œ Top 5 Demand Drivers:')\n",
    "for feat, score in feat_imp.nlargest(5).items():\n",
    "    print(f'   â€¢ {feat:30s}: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš¨ Section 6: Stockout Risk Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ STOCKOUT RISK FEATURES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "STOCK_FEATURES = [\n",
    "    'year','month','week','day_of_week','quarter','is_weekend',\n",
    "    'category_enc','store_location_enc','product_name_enc','promotion_type_enc',\n",
    "    'unit_price','inventory_level','reorder_point','stock_health',\n",
    "    'days_of_stock','actual_demand','forecasted_demand',\n",
    "    'forecast_error','is_promotion','excess_inventory'\n",
    "]\n",
    "\n",
    "X_cls = df_ml_sorted[STOCK_FEATURES].fillna(0)\n",
    "y_cls = df_ml_sorted['stockout_indicator']\n",
    "\n",
    "# Time-based split for classifier too\n",
    "X_tr, X_te = X_cls.iloc[:split_idx], X_cls.iloc[split_idx:]\n",
    "y_tr, y_te = y_cls.iloc[:split_idx], y_cls.iloc[split_idx:]\n",
    "\n",
    "print(f'Class distribution in training set:')\n",
    "print(y_tr.value_counts(normalize=True).rename({0:'No Stockout', 1:'Stockout'}).to_string())\n",
    "\n",
    "# â”€â”€ HYPERPARAMETER TUNING FOR CLASSIFIER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "clf_params = {\n",
    "    'n_estimators'  : [100, 200, 300],\n",
    "    'max_depth'     : [5, 8, 10],\n",
    "    'min_samples_leaf': [3, 5, 10],\n",
    "}\n",
    "\n",
    "clf_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    param_distributions = clf_params,\n",
    "    n_iter      = 10,\n",
    "    cv          = tscv,\n",
    "    scoring     = 'roc_auc',\n",
    "    random_state= 42,\n",
    "    n_jobs      = -1\n",
    ")\n",
    "clf_search.fit(X_tr, y_tr)\n",
    "\n",
    "rf_clf    = clf_search.best_estimator_\n",
    "y_pred    = rf_clf.predict(X_te)\n",
    "y_prob    = rf_clf.predict_proba(X_te)[:, 1]\n",
    "\n",
    "print(f'\\nâœ… Stockout Classifier â€” Best CV AUC: {clf_search.best_score_:.4f}')\n",
    "print(f'   Test Accuracy : {accuracy_score(y_te, y_pred):.4f}')\n",
    "print(f'   Test AUC-ROC  : {roc_auc_score(y_te, y_prob):.4f}')\n",
    "print()\n",
    "print(classification_report(y_te, y_pred, target_names=['No Stockout','Stockout Risk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CLASSIFIER VISUALIZATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "fig.suptitle('Stockout Risk Classifier â€” Evaluation', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_te, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['No Stockout','Stockout'],\n",
    "            yticklabels=['No Stockout','Stockout'],\n",
    "            annot_kws={'size': 14, 'weight': 'bold'})\n",
    "axes[0].set_title('Confusion Matrix', fontweight='bold')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_te, y_prob)\n",
    "auc_val     = roc_auc_score(y_te, y_prob)\n",
    "axes[1].plot(fpr, tpr, color='#2196F3', lw=2.5, label=f'ROC Curve (AUC = {auc_val:.4f})')\n",
    "axes[1].plot([0,1],[0,1], 'r--', lw=1.5, label='Random Classifier')\n",
    "axes[1].fill_between(fpr, tpr, alpha=0.1, color='#2196F3')\n",
    "axes[1].set_title('ROC-AUC Curve', fontweight='bold')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].legend()\n",
    "\n",
    "# Feature Importance for Classifier\n",
    "clf_fi = pd.Series(rf_clf.feature_importances_, index=STOCK_FEATURES).sort_values().tail(10)\n",
    "axes[2].barh(clf_fi.index, clf_fi.values, color='#FF5722')\n",
    "axes[2].set_title('Top 10 Stockout Risk Drivers', fontweight='bold')\n",
    "axes[2].set_xlabel('Feature Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/stockout_classifier.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ RISK SCORING TABLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_ml['stockout_risk_prob'] = rf_clf.predict_proba(X_cls)[:, 1]\n",
    "df_ml['risk_level'] = pd.cut(\n",
    "    df_ml['stockout_risk_prob'],\n",
    "    bins=[0, 0.3, 0.6, 1.0],\n",
    "    labels=['ğŸŸ¢ Low', 'ğŸŸ¡ Medium', 'ğŸ”´ High']\n",
    ")\n",
    "\n",
    "risk_table = (\n",
    "    df_ml.groupby(['product_name','store_location'], as_index=False)\n",
    "    .agg(\n",
    "        risk_score   = ('stockout_risk_prob', 'mean'),\n",
    "        avg_inventory= ('inventory_level', 'mean'),\n",
    "        avg_demand   = ('actual_demand', 'mean'),\n",
    "        risk_level   = ('risk_level', lambda x: x.mode()[0])\n",
    "    )\n",
    "    .sort_values('risk_score', ascending=False)\n",
    ")\n",
    "\n",
    "print('\\nğŸš¨ TOP 20 HIGH-RISK PRODUCTS â€” Immediate Action Required')\n",
    "print('='*80)\n",
    "print(risk_table.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“… Section 7: 30-Day Revenue Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ BUILD TIME SERIES FEATURES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "daily_rev = (\n",
    "    df.groupby('transaction_date')['revenue']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .sort_values('transaction_date')\n",
    "    .set_index('transaction_date')\n",
    ")\n",
    "\n",
    "daily_rev['day_num']    = range(len(daily_rev))\n",
    "daily_rev['dow']        = daily_rev.index.dayofweek\n",
    "daily_rev['month']      = daily_rev.index.month\n",
    "daily_rev['quarter']    = daily_rev.index.quarter\n",
    "daily_rev['is_weekend'] = (daily_rev['dow'] >= 5).astype(int)\n",
    "daily_rev['lag_7']      = daily_rev['revenue'].shift(7).bfill()\n",
    "daily_rev['lag_14']     = daily_rev['revenue'].shift(14).bfill()\n",
    "daily_rev['lag_30']     = daily_rev['revenue'].shift(30).bfill()\n",
    "daily_rev['roll_7']     = daily_rev['revenue'].rolling(7,  min_periods=1).mean()\n",
    "daily_rev['roll_14']    = daily_rev['revenue'].rolling(14, min_periods=1).mean()\n",
    "daily_rev['roll_30']    = daily_rev['revenue'].rolling(30, min_periods=1).mean()\n",
    "\n",
    "TS_FEATS = ['day_num','dow','month','quarter','is_weekend',\n",
    "            'lag_7','lag_14','lag_30','roll_7','roll_14','roll_30']\n",
    "\n",
    "X_ts = daily_rev[TS_FEATS]\n",
    "y_ts = daily_rev['revenue']\n",
    "\n",
    "# Time-based split for time series model\n",
    "ts_split   = int(len(X_ts) * 0.8)\n",
    "X_ts_tr, X_ts_te = X_ts.iloc[:ts_split], X_ts.iloc[ts_split:]\n",
    "y_ts_tr, y_ts_te = y_ts.iloc[:ts_split], y_ts.iloc[ts_split:]\n",
    "\n",
    "ts_model = GradientBoostingRegressor(\n",
    "    n_estimators=300, learning_rate=0.05,\n",
    "    max_depth=4, subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "ts_model.fit(X_ts_tr, y_ts_tr)\n",
    "\n",
    "ts_test_pred = ts_model.predict(X_ts_te)\n",
    "ts_r2   = r2_score(y_ts_te, ts_test_pred)\n",
    "ts_rmse = np.sqrt(mean_squared_error(y_ts_te, ts_test_pred))\n",
    "print(f'âœ… Revenue Forecast Model â€” RÂ²={ts_r2:.4f} | RMSE=${ts_rmse:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ GENERATE 30-DAY FORECAST â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "last_date    = daily_rev.index.max()\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30)\n",
    "\n",
    "recent_revenue = list(daily_rev['revenue'].tail(30).values)\n",
    "last_day_num   = daily_rev['day_num'].iloc[-1]\n",
    "\n",
    "forecast_rows = []\n",
    "for i, date in enumerate(future_dates):\n",
    "    r7   = np.mean(recent_revenue[-7:])\n",
    "    r14  = np.mean(recent_revenue[-14:])\n",
    "    r30  = np.mean(recent_revenue[-30:])\n",
    "    l7   = recent_revenue[-7]\n",
    "    l14  = recent_revenue[-14] if len(recent_revenue) >= 14 else recent_revenue[0]\n",
    "    l30  = recent_revenue[-30] if len(recent_revenue) >= 30 else recent_revenue[0]\n",
    "    row  = [last_day_num+i+1, date.dayofweek, date.month, date.quarter,\n",
    "            int(date.dayofweek>=5), l7, l14, l30, r7, r14, r30]\n",
    "    pred = max(0, ts_model.predict([row])[0])\n",
    "    recent_revenue.append(pred)\n",
    "    forecast_rows.append({'date': date, 'predicted_revenue': pred})\n",
    "\n",
    "forecast_df = pd.DataFrame(forecast_rows).set_index('date')\n",
    "\n",
    "# â”€â”€ PLOT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "fig.suptitle('30-Day Revenue Forecast', fontsize=15, fontweight='bold')\n",
    "\n",
    "# Plot 1: Forecast\n",
    "ax = axes[0]\n",
    "last_60 = daily_rev['revenue'].tail(60)\n",
    "ax.plot(last_60.index, last_60.values, color='#2196F3', lw=2, label='Historical (Last 60 Days)')\n",
    "ax.plot(forecast_df.index, forecast_df['predicted_revenue'],\n",
    "        color='#FF9800', lw=2.5, linestyle='--', marker='o', markersize=4, label='30-Day Forecast')\n",
    "ax.fill_between(forecast_df.index,\n",
    "                forecast_df['predicted_revenue'] * 0.88,\n",
    "                forecast_df['predicted_revenue'] * 1.12,\n",
    "                alpha=0.2, color='#FF9800', label='Â±12% Confidence Band')\n",
    "ax.axvline(x=last_date, color='red', linestyle=':', lw=2, label='Forecast Starts Here')\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x,p: f'${x:,.0f}'))\n",
    "ax.set_title('Revenue Forecast with Confidence Band', fontweight='bold')\n",
    "ax.set_ylabel('Daily Revenue (USD)')\n",
    "ax.legend()\n",
    "ax.tick_params(axis='x', rotation=30)\n",
    "\n",
    "# Plot 2: Weekly Aggregated Forecast\n",
    "ax2 = axes[1]\n",
    "forecast_df['week_num'] = (forecast_df.index - forecast_df.index[0]).days // 7 + 1\n",
    "weekly_forecast = forecast_df.groupby('week_num')['predicted_revenue'].sum()\n",
    "bars = ax2.bar(weekly_forecast.index, weekly_forecast.values,\n",
    "               color=['#4CAF50','#2196F3','#FF9800','#9C27B0','#F44336'][:len(weekly_forecast)],\n",
    "               width=0.6, alpha=0.85)\n",
    "for bar, val in zip(bars, weekly_forecast.values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 200,\n",
    "             f'${val:,.0f}', ha='center', fontweight='bold', fontsize=10)\n",
    "ax2.set_title('Weekly Revenue Forecast Breakdown', fontweight='bold')\n",
    "ax2.set_xlabel('Week Number')\n",
    "ax2.set_ylabel('Projected Revenue (USD)')\n",
    "ax2.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x,p: f'${x:,.0f}'))\n",
    "ax2.set_xticks(weekly_forecast.index)\n",
    "ax2.set_xticklabels([f'Week {w}' for w in weekly_forecast.index])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/revenue_forecast.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "total_forecast = forecast_df['predicted_revenue'].sum()\n",
    "print(f'\\nğŸ“Š 30-Day Forecast Summary:')\n",
    "print(f'   Total Projected Revenue : ${total_forecast:>12,.2f}')\n",
    "print(f'   Daily Average           : ${forecast_df[\"predicted_revenue\"].mean():>12,.2f}')\n",
    "print(f'   Best Day                : {forecast_df[\"predicted_revenue\"].idxmax().date()} (${forecast_df[\"predicted_revenue\"].max():,.2f})')\n",
    "print(f'   Weakest Day             : {forecast_df[\"predicted_revenue\"].idxmin().date()} (${forecast_df[\"predicted_revenue\"].min():,.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Section 8: Inventory Optimization â€” EOQ + Safety Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ EOQ + SAFETY STOCK MODEL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ORDERING_COST  = 50    # $ per order\n",
    "HOLDING_RATE   = 0.20  # 20% of unit price/year\n",
    "LEAD_TIME_DAYS = 7\n",
    "SERVICE_FACTOR = 1.65  # 95% service level\n",
    "\n",
    "product_stats = df.groupby(['product_name','category'], as_index=False).agg(\n",
    "    avg_daily_demand  = ('actual_demand',   'mean'),\n",
    "    std_demand        = ('actual_demand',   'std'),\n",
    "    avg_unit_price    = ('unit_price',      'mean'),\n",
    "    avg_inventory     = ('inventory_level', 'mean'),\n",
    "    avg_reorder_point = ('reorder_point',   'mean'),\n",
    "    total_revenue     = ('revenue',         'sum'),\n",
    "    stockout_rate     = ('stockout_indicator','mean'),\n",
    ")\n",
    "product_stats = product_stats.reset_index(drop=True)\n",
    "product_stats['std_demand'] = product_stats['std_demand'].fillna(0)\n",
    "\n",
    "annual_demand  = product_stats['avg_daily_demand'] * 365\n",
    "holding_cost   = (product_stats['avg_unit_price'] * HOLDING_RATE).replace(0, 0.01)\n",
    "eoq            = np.sqrt((2 * annual_demand * ORDERING_COST) / holding_cost).round(0)\n",
    "safety_stock   = (SERVICE_FACTOR * product_stats['std_demand'] * np.sqrt(LEAD_TIME_DAYS)).round(0)\n",
    "recommended    = (product_stats['avg_daily_demand'] * LEAD_TIME_DAYS + safety_stock).round(0)\n",
    "gap            = product_stats['avg_inventory'] - recommended\n",
    "\n",
    "product_stats = product_stats.assign(\n",
    "    EOQ                    = eoq,\n",
    "    safety_stock           = safety_stock,\n",
    "    recommended_reorder    = recommended,\n",
    "    current_vs_recommended = gap,\n",
    "    holding_cost_annual    = (product_stats['avg_inventory'] * product_stats['avg_unit_price'] * HOLDING_RATE).round(2),\n",
    "    action = gap.apply(\n",
    "        lambda x: 'ğŸ”´ REORDER NOW' if x < 0 else ('ğŸŸ¡ MONITOR' if x < 100 else 'ğŸŸ¢ SUFFICIENT')\n",
    "    )\n",
    ")\n",
    "\n",
    "print('\\nğŸ“‹ INVENTORY OPTIMIZATION REPORT')\n",
    "print('='*90)\n",
    "print('\\nğŸ”´ Products Requiring Immediate Reorder:')\n",
    "cols = ['product_name','avg_inventory','recommended_reorder','EOQ','safety_stock','action']\n",
    "print(\n",
    "    product_stats\n",
    "    .sort_values('current_vs_recommended')\n",
    "    .head(15)[cols]\n",
    "    .to_string(index=False)\n",
    ")\n",
    "\n",
    "reorder_count  = (product_stats['action'] == 'ğŸ”´ REORDER NOW').sum()\n",
    "monitor_count  = (product_stats['action'] == 'ğŸŸ¡ MONITOR').sum()\n",
    "ok_count       = (product_stats['action'] == 'ğŸŸ¢ SUFFICIENT').sum()\n",
    "total_holding  = product_stats['holding_cost_annual'].sum()\n",
    "\n",
    "print(f'\\nğŸ“Š Summary:')\n",
    "print(f'   ğŸ”´ Reorder Now  : {reorder_count} products')\n",
    "print(f'   ğŸŸ¡ Monitor      : {monitor_count} products')\n",
    "print(f'   ğŸŸ¢ Sufficient   : {ok_count} products')\n",
    "print(f'   ğŸ’¸ Total Annual Holding Cost : ${total_holding:,.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ INVENTORY VISUALIZATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "fig.suptitle('Inventory Optimization Analysis', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 1: Action Distribution\n",
    "action_counts = product_stats['action'].value_counts()\n",
    "color_map = {'ğŸ”´ REORDER NOW':'#F44336','ğŸŸ¡ MONITOR':'#FF9800','ğŸŸ¢ SUFFICIENT':'#4CAF50'}\n",
    "bar_colors = [color_map.get(a, 'gray') for a in action_counts.index]\n",
    "bars = axes[0].bar(action_counts.index, action_counts.values, color=bar_colors, width=0.5)\n",
    "for bar, val in zip(bars, action_counts.values):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                 str(val), ha='center', fontweight='bold', fontsize=12)\n",
    "axes[0].set_title('Inventory Action Required', fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Products')\n",
    "\n",
    "# Plot 2: Current vs Recommended for bottom 12 products\n",
    "bottom12 = product_stats.nsmallest(12, 'current_vs_recommended')\n",
    "x = np.arange(len(bottom12))\n",
    "axes[1].bar(x - 0.2, bottom12['avg_inventory'],    width=0.4, label='Current Inventory',   color='#2196F3', alpha=0.8)\n",
    "axes[1].bar(x + 0.2, bottom12['recommended_reorder'], width=0.4, label='Recommended Level', color='#FF9800', alpha=0.8)\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(bottom12['product_name'], rotation=45, ha='right', fontsize=8)\n",
    "axes[1].set_title('Products Needing Reorder', fontweight='bold')\n",
    "axes[1].set_ylabel('Units')\n",
    "axes[1].legend()\n",
    "\n",
    "# Plot 3: Holding Cost by Category\n",
    "cat_holding = product_stats.groupby('category')['holding_cost_annual'].sum().sort_values(ascending=True)\n",
    "axes[2].barh(cat_holding.index, cat_holding.values, color=COLORS[:len(cat_holding)])\n",
    "for i, val in enumerate(cat_holding.values):\n",
    "    axes[2].text(val + 100, i, f'${val:,.0f}', va='center', fontsize=9, fontweight='bold')\n",
    "axes[2].set_title('Annual Holding Cost by Category', fontweight='bold')\n",
    "axes[2].set_xlabel('Holding Cost (USD/Year)')\n",
    "axes[2].xaxis.set_major_formatter(ticker.FuncFormatter(lambda x,p: f'${x/1e3:.0f}K'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/inventory_optimization.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸª Section 9: Store Performance Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ STORE KPIs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if 'buyer_type' not in df.columns:\n",
    "    opc = df.groupby('customer_id')['transaction_id'].count().reset_index()\n",
    "    opc.rename(columns={'transaction_id':'order_count'}, inplace=True)\n",
    "    opc['buyer_type'] = opc['order_count'].apply(lambda x: 'Repeat Buyer' if x > 1 else 'One-time Buyer')\n",
    "    df = df.merge(opc[['customer_id','buyer_type']], on='customer_id', how='left')\n",
    "\n",
    "store_kpis = df.groupby('store_location', as_index=False).agg(\n",
    "    total_revenue    = ('revenue',            'sum'),\n",
    "    avg_order_value  = ('revenue',            'mean'),\n",
    "    stockout_rate    = ('stockout_indicator', 'mean'),\n",
    "    forecast_error   = ('forecast_error',     'mean'),\n",
    "    total_qty        = ('quantity_sold',      'sum'),\n",
    "    repeat_rate      = ('buyer_type',         lambda x: (x == 'Repeat Buyer').mean()),\n",
    "    lost_revenue     = ('lost_revenue',       'sum'),\n",
    ")\n",
    "\n",
    "store_kpis['revenue_rank'] = store_kpis['total_revenue'].rank(ascending=False).astype(int)\n",
    "store_kpis['segment']      = pd.cut(\n",
    "    store_kpis['total_revenue'], bins=3,\n",
    "    labels=['ğŸ”´ Low Performer','ğŸŸ¡ Mid Performer','ğŸŸ¢ Top Performer']\n",
    ")\n",
    "\n",
    "print('\\nğŸª STORE PERFORMANCE SCORECARD')\n",
    "print('='*100)\n",
    "print(\n",
    "    store_kpis\n",
    "    .sort_values('total_revenue', ascending=False)\n",
    "    [['store_location','total_revenue','avg_order_value','stockout_rate','repeat_rate','lost_revenue','segment']]\n",
    "    .to_string(index=False)\n",
    ")\n",
    "\n",
    "# Store Performance Matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Bubble Chart\n",
    "scatter = axes[0].scatter(\n",
    "    store_kpis['stockout_rate'],\n",
    "    store_kpis['total_revenue'],\n",
    "    s = store_kpis['avg_order_value'] * 3,\n",
    "    c = store_kpis['forecast_error'],\n",
    "    cmap='RdYlGn_r', alpha=0.85, edgecolors='black', linewidths=1\n",
    ")\n",
    "for _, row in store_kpis.iterrows():\n",
    "    axes[0].annotate(\n",
    "        row['store_location'],\n",
    "        (row['stockout_rate'], row['total_revenue']),\n",
    "        textcoords='offset points', xytext=(8, 4), fontsize=9, fontweight='bold'\n",
    "    )\n",
    "plt.colorbar(scatter, ax=axes[0], label='Avg Forecast Error')\n",
    "axes[0].axvline(store_kpis['stockout_rate'].mean(), color='red',  linestyle='--', alpha=0.5)\n",
    "axes[0].axhline(store_kpis['total_revenue'].mean(), color='blue', linestyle='--', alpha=0.5)\n",
    "axes[0].set_xlabel('Stockout Rate (lower = better)')\n",
    "axes[0].set_ylabel('Total Revenue')\n",
    "axes[0].set_title('Store Performance Matrix\\n(Bubble=AOV | Color=Forecast Error)', fontweight='bold')\n",
    "axes[0].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x,p: f'${x/1e6:.1f}M'))\n",
    "\n",
    "# Lost Revenue by Store\n",
    "store_sorted = store_kpis.sort_values('lost_revenue', ascending=True)\n",
    "axes[1].barh(store_sorted['store_location'], store_sorted['lost_revenue'], color='#F44336', alpha=0.8)\n",
    "for i, val in enumerate(store_sorted['lost_revenue']):\n",
    "    axes[1].text(val + 1000, i, f'${val:,.0f}', va='center', fontsize=9)\n",
    "axes[1].set_title('Lost Revenue by Store Location', fontweight='bold')\n",
    "axes[1].set_xlabel('Lost Revenue (USD)')\n",
    "axes[1].xaxis.set_major_formatter(ticker.FuncFormatter(lambda x,p: f'${x/1e3:.0f}K'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/store_performance.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Section 10: Model Persistence â€” Production Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ SAVE ALL MODELS & ARTIFACTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# This is what MNC production teams do â€” serialize models for deployment\n",
    "\n",
    "# Save ML models\n",
    "joblib.dump(best_model,  'models/demand_forecast_model.pkl')\n",
    "joblib.dump(rf_clf,      'models/stockout_classifier.pkl')\n",
    "joblib.dump(ts_model,    'models/revenue_forecast_model.pkl')\n",
    "joblib.dump(encoders,    'models/label_encoders.pkl')\n",
    "\n",
    "# Save model metadata as JSON\n",
    "model_metadata = {\n",
    "    'created_at'          : datetime.now().strftime('%Y-%m-%d %H:%M'),\n",
    "    'demand_model'        : best_model_name,\n",
    "    'demand_r2'           : float(results_df.iloc[0]['RÂ² Score']),\n",
    "    'demand_rmse'         : float(results_df.iloc[0]['RMSE']),\n",
    "    'demand_mape'         : float(results_df.iloc[0]['MAPE (%)']),\n",
    "    'classifier_auc'      : float(round(roc_auc_score(y_te, y_prob), 4)),\n",
    "    'classifier_accuracy' : float(round(accuracy_score(y_te, y_pred), 4)),\n",
    "    'features_used'       : DEMAND_FEATURES,\n",
    "    'training_records'    : len(X_train),\n",
    "    'best_params'         : rf_search.best_params_,\n",
    "}\n",
    "\n",
    "with open('models/model_metadata.json', 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=4)\n",
    "\n",
    "print('âœ… All models saved to /models folder:')\n",
    "for f in os.listdir('models'):\n",
    "    size = os.path.getsize(f'models/{f}')\n",
    "    print(f'   ğŸ“„ {f:45s} ({size/1024:.1f} KB)')\n",
    "\n",
    "print('\\nâœ… All charts saved to /reports folder:')\n",
    "for f in os.listdir('reports'):\n",
    "    size = os.path.getsize(f'reports/{f}')\n",
    "    print(f'   ğŸ–¼ï¸  {f:45s} ({size/1024:.1f} KB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ DEMONSTRATE MODEL LOADING (Deployment Simulation) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# This shows how a deployed API would use the saved model\n",
    "\n",
    "print('ğŸ”„ Simulating Production Deployment...')\n",
    "print('   (Loading saved models just like an API server would)\\n')\n",
    "\n",
    "loaded_model    = joblib.load('models/demand_forecast_model.pkl')\n",
    "loaded_encoders = joblib.load('models/label_encoders.pkl')\n",
    "\n",
    "# Simulate a real-time prediction request\n",
    "sample_input = X_test.iloc[[0]]\n",
    "live_prediction = loaded_model.predict(sample_input)[0]\n",
    "actual_value    = y_test.iloc[0]\n",
    "\n",
    "print('   ğŸ“¡ Live Prediction Request:')\n",
    "print(f'   Predicted Demand : {live_prediction:.0f} units')\n",
    "print(f'   Actual Demand    : {actual_value:.0f} units')\n",
    "print(f'   Error            : {abs(live_prediction - actual_value):.0f} units ({abs(live_prediction - actual_value)/actual_value*100:.1f}%)')\n",
    "print('\\nâœ… Model loaded and serving predictions successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Section 11: Business Impact Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ DOLLAR IMPACT OF ML MODELS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "baseline_mape  = results_df[results_df['Model'] == 'Linear Regression']['MAPE (%)'].values[0]\n",
    "best_mape      = results_df.iloc[0]['MAPE (%)']\n",
    "mape_improve   = baseline_mape - best_mape\n",
    "revenue_at_risk= df['lost_revenue'].sum()\n",
    "model_saving   = revenue_at_risk * (mape_improve / 100)\n",
    "\n",
    "stockout_recovery  = revenue_at_risk * 0.30\n",
    "overstock_saving   = product_stats['holding_cost_annual'].sum() * 0.20\n",
    "retention_upside   = total_revenue  * 0.05\n",
    "\n",
    "total_impact = stockout_recovery + overstock_saving + retention_upside\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('       ğŸ’° BUSINESS IMPACT QUANTIFICATION REPORT')\n",
    "print('='*70)\n",
    "print(f'  Baseline Forecast MAPE (Linear Reg)  : {baseline_mape:.2f}%')\n",
    "print(f'  Best Model MAPE ({best_model_name[:20]:20s}) : {best_mape:.2f}%')\n",
    "print(f'  MAPE Improvement                      : {mape_improve:.2f}%')\n",
    "print()\n",
    "print(f'  ğŸ“‰ Total Lost Revenue (Current)       : ${revenue_at_risk:>12,.0f}')\n",
    "print(f'  âœ… Stockout Recovery (30%)             : ${stockout_recovery:>12,.0f}')\n",
    "print(f'  ğŸ“¦ Overstock Cost Savings (20%)        : ${overstock_saving:>12,.0f}')\n",
    "print(f'  ğŸ”„ Retention Improvement (5%)          : ${retention_upside:>12,.0f}')\n",
    "print(f'  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')\n",
    "print(f'  ğŸ’° TOTAL PROJECTED ANNUAL IMPACT       : ${total_impact:>12,.0f}')\n",
    "print('='*70)\n",
    "print(f'\\n  ğŸ“… 30-Day Revenue Forecast             : ${total_forecast:>12,.0f}')\n",
    "print(f'  ğŸš¨ Products at High Stockout Risk      : {(risk_table[\"risk_score\"] > 0.6).sum():>12}')\n",
    "print(f'  ğŸ”´ Products Needing Immediate Reorder  : {reorder_count:>12}')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ FINAL IMPACT VISUALIZATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Business Impact Summary', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Impact breakdown\n",
    "impact_items   = ['Stockout\\nRecovery', 'Overstock\\nSavings', 'Retention\\nUpside']\n",
    "impact_values  = [stockout_recovery, overstock_saving, retention_upside]\n",
    "impact_colors  = ['#4CAF50', '#2196F3', '#FF9800']\n",
    "\n",
    "bars = axes[0].bar(impact_items, impact_values, color=impact_colors, alpha=0.85, width=0.5)\n",
    "for bar, val in zip(bars, impact_values):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 500,\n",
    "                 f'${val:,.0f}', ha='center', fontweight='bold', fontsize=11)\n",
    "axes[0].set_title(f'Projected Annual Savings\\nTotal: ${total_impact:,.0f}', fontweight='bold')\n",
    "axes[0].set_ylabel('USD')\n",
    "axes[0].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x,p: f'${x/1e3:.0f}K'))\n",
    "\n",
    "# Model performance comparison\n",
    "axes[1].barh(results_df['Model'], results_df['RÂ² Score'],\n",
    "             color=COLORS[:len(results_df)], alpha=0.85)\n",
    "for i, (_, row) in enumerate(results_df.iterrows()):\n",
    "    axes[1].text(row['RÂ² Score'] + 0.005, i,\n",
    "                 f'RÂ²={row[\"RÂ² Score\"]:.4f} | MAPE={row[\"MAPE (%)\"]:.1f}%',\n",
    "                 va='center', fontsize=9)\n",
    "axes[1].set_xlim(0, 1.2)\n",
    "axes[1].set_title('Model Performance Leaderboard', fontweight='bold')\n",
    "axes[1].set_xlabel('RÂ² Score')\n",
    "axes[1].axvline(1.0, color='red', linestyle='--', alpha=0.4, label='Perfect Score')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/business_impact.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Section 12: Final Strategic Action Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘          ğŸ¢ WALMART INVENTORY INTELLIGENCE â€” FINAL REPORT              â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  ğŸ”´ WEEK 1 â€” IMMEDIATE ACTIONS:                                         â•‘\n",
    "â•‘    â€¢ Trigger reorder for all ğŸ”´ REORDER NOW products immediately        â•‘\n",
    "â•‘    â€¢ Prioritize Electronics & Appliances (highest revenue risk)          â•‘\n",
    "â•‘    â€¢ Alert store managers in high-stockout locations                     â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  ğŸŸ¡ MONTH 1 â€” SHORT-TERM:                                               â•‘\n",
    "â•‘    â€¢ Deploy demand_forecast_model.pkl into inventory system              â•‘\n",
    "â•‘    â€¢ Replace existing forecasted_demand with ML predictions              â•‘\n",
    "â•‘    â€¢ Implement safety stock levels from EOQ model output                 â•‘\n",
    "â•‘    â€¢ Set up weekly model retraining pipeline                             â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  ğŸŸ¢ QUARTER 1 â€” STRATEGIC:                                              â•‘\n",
    "â•‘    â€¢ Build real-time dashboard (Dash/PowerBI) using saved reports        â•‘\n",
    "â•‘    â€¢ Wrap models in FastAPI for live prediction endpoint                 â•‘\n",
    "â•‘    â€¢ Add MLflow for experiment tracking                                  â•‘\n",
    "â•‘    â€¢ Customer retention program targeting 74.9% one-time buyers         â•‘\n",
    "â•‘    â€¢ Expand to price optimization model                                  â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘  ğŸ“ DELIVERABLES PRODUCED BY THIS NOTEBOOK:                             â•‘\n",
    "â•‘    models/demand_forecast_model.pkl   â†’ Deploy to production            â•‘\n",
    "â•‘    models/stockout_classifier.pkl     â†’ Deploy to production            â•‘\n",
    "â•‘    models/revenue_forecast_model.pkl  â†’ Deploy to production            â•‘\n",
    "â•‘    models/label_encoders.pkl          â†’ Required for inference          â•‘\n",
    "â•‘    models/model_metadata.json         â†’ Track model versions            â•‘\n",
    "â•‘    reports/kpi_dashboard.png          â†’ Share with stakeholders         â•‘\n",
    "â•‘    reports/revenue_forecast.png       â†’ Share with finance team         â•‘\n",
    "â•‘    reports/business_impact.png        â†’ Share with management           â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "print('\\nğŸ Analysis Complete!')\n",
    "print(f'   Completed at: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ—ºï¸ Next Steps to Make This Even Stronger\n",
    "\n",
    "| Step | Tool | Why It Matters |\n",
    "|------|------|----------------|\n",
    "| Model Explainability | `shap` library | Makes ML decisions transparent to business |\n",
    "| Better Gradient Boosting | `xgboost` / `lightgbm` | Typically 5â€“10% better than sklearn GBM |\n",
    "| Experiment Tracking | `mlflow` | Standard in MNC ML teams |\n",
    "| API Deployment | `FastAPI` + `uvicorn` | Serve real-time predictions |\n",
    "| Interactive Dashboard | `plotly dash` | Executive-ready live reporting |\n",
    "| A/B Testing Framework | Custom | Test model versions in production |\n",
    "\n",
    "---\n",
    "**Tech Stack:** Python Â· pandas Â· scikit-learn Â· matplotlib Â· seaborn Â· joblib  \n",
    "**ML Techniques:** TimeSeriesSplit CV Â· RandomizedSearchCV Â· RandomForest Â· GradientBoosting Â· ROC-AUC Â· EOQ Model  \n",
    "**Output:** 3 production-ready models + 6 business reports"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
